{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Hyperparameter Configuration\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 100,\n",
    "    'LEARNING_RATE': 1e-6,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'SEED': 41\n",
    "}\n",
    "\n",
    "# 설정 및 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, 29)\n",
    "model.load_state_dict(torch.load('data/save_data/saved/best_model2.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# GradCAM 설정\n",
    "gradcam = GradCAM(model, model.layer4)\n",
    "\n",
    "\n",
    "# 이미지 전처리를 위한 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "dataset = ImageFolder(root='./INSECT_CLASSIFICATION/FINAL/', transform=train_transforms)\n",
    "\n",
    "class_counts = [0] * 29\n",
    "for _, label in dataset:\n",
    "    class_counts[label] += 1\n",
    "class_names = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert numpy image (from OpenCV) to PIL Image\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # 이미지 전처리\n",
    "    img_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 예측 및 GradCAM 생성\n",
    "    preds = model(img_tensor)\n",
    "    _, predicted = preds.max(1)\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    \n",
    "    # 원본 이미지에 예측된 클래스 이름 표시\n",
    "    # cv2.putText(frame, predicted_class, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    mask = gradcam(img_tensor, class_idx=predicted.item())\n",
    "    \n",
    "    # 원본 이미지와 Grad-CAM 시각화 병합\n",
    "    heatmap = (mask[0].cpu() - mask[0].cpu().min()) / (mask[0].cpu().max() - mask[0].cpu().min()) # Normalize the mask\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = heatmap.squeeze()  # Ensure heatmap is 2D\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap_resized = cv2.resize(heatmap, (frame.shape[1], frame.shape[0]))  # Resize heatmap to match frame\n",
    "    heatmap_resized = np.float32(heatmap_resized) / 255\n",
    "    \n",
    "    # Overlaying the heatmap on the original image\n",
    "    cam_img = cv2.addWeighted(frame, 0.6, (heatmap_resized * 255).astype(np.uint8), 0.4, 0)\n",
    "    \n",
    "    # Add species name with white background and black text to the cam_img\n",
    "    label_size = cv2.getTextSize(predicted_class, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "    cam_img[10:10+label_size[1]+8, 10:10+label_size[0]+8] = [255, 255, 255]\n",
    "    cv2.putText(cam_img, predicted_class, (15, 10+label_size[1]+3), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 결과 표시\n",
    "    # cv2.imshow('Webcam', frame)\n",
    "    cv2.imshow('Grad-CAM', cam_img)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27: # ESC 키를 누르면 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcc704823a757e1539f5a43af79350a02135e44c06252b04666ddd79fc40e3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
